{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models, metrics, optimizers, losses, callbacks\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from utils.model_inference_plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('data/final_model_data_all_scaled.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Bx', 'By', 'Bz', 'Bx_lag_1', 'Bx_lag_2', 'By_lag_1',\n",
    "        'By_lag_2', 'Bz_lag_1', 'Bz_lag_2', 'Bx_conditional_vol',\n",
    "        'By_conditional_vol', 'Bz_conditional_vol', 'Bx_rolling_stdev',\n",
    "        'By_rolling_stdev', 'Bz_rolling_stdev']].values\n",
    "\n",
    "y = df['Event_label_80'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = len(X)\n",
    "n_features = X.shape[1]\n",
    "\n",
    "train_size = int(0.8 * total_samples)\n",
    "test_size = total_samples - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "n_timesteps = 500\n",
    "stride = 40\n",
    "\n",
    "def generate_timeseries(X, y, n_timesteps, batch_size, start_idx, end_idx, stride):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        y_seq_batch = []\n",
    "\n",
    "        for i in range(start_idx + n_timesteps, end_idx, stride):\n",
    "            X_batch.append(X[i - n_timesteps:i, :])\n",
    "            y_batch.append(y[i - n_timesteps:i].reshape(-1, 1))\n",
    "            y_seq_batch.append([np.mean(y[i - n_timesteps:i]).astype(np.float32)])\n",
    "\n",
    "            if len(X_batch) == batch_size:\n",
    "                yield (\n",
    "                    tf.convert_to_tensor(np.array(X_batch), dtype=tf.float32),\n",
    "                    {\n",
    "                        \"time_output\": tf.convert_to_tensor(np.array(y_batch), dtype=tf.float32),\n",
    "                        \"sequence_output\": tf.convert_to_tensor(np.array(y_seq_batch), dtype=tf.float32)\n",
    "                    }\n",
    "                )\n",
    "                X_batch, y_batch, y_seq_batch = [], [], []\n",
    "        \n",
    "        if len(X_batch) > 0:\n",
    "            yield (\n",
    "                tf.convert_to_tensor(np.array(X_batch), dtype=tf.float32),\n",
    "                {\n",
    "                    \"time_output\": tf.convert_to_tensor(np.array(y_batch), dtype=tf.float32),\n",
    "                    \"sequence_output\": tf.convert_to_tensor(np.array(y_seq_batch), dtype=tf.float32)\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "train_idx = (0, train_size)\n",
    "test_idx = (train_size, total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(start_idx, end_idx):\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        lambda: generate_timeseries(X, y, n_timesteps=n_timesteps, batch_size=batch_size,\n",
    "                                    start_idx=start_idx, end_idx=end_idx, stride=stride),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, n_timesteps, X.shape[1]), dtype=tf.float32),\n",
    "            {\n",
    "                \"time_output\": tf.TensorSpec(shape=(None, n_timesteps, 1), dtype=tf.float32),\n",
    "                \"sequence_output\": tf.TensorSpec(shape=(None, 1), dtype=tf.float32)\n",
    "            }\n",
    "        )\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = create_dataset(train_idx[0], train_idx[1])\n",
    "test_dataset = create_dataset(test_idx[0], test_idx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_train_epoch = int(np.ceil((train_size - n_timesteps) / (stride * batch_size)))\n",
    "steps_test_epoch = int(np.ceil((test_size - n_timesteps) / (stride * batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_ratios = []\n",
    "\n",
    "# for _, outputs in test_dataset.take(steps_train_epoch):\n",
    "#     y_time = outputs['time_output'].numpy()\n",
    "#     has_event = (np.sum(y_time, axis=1) > 0).astype(np.float32)\n",
    "    \n",
    "#     batch_ratios.append(np.mean(has_event))\n",
    "\n",
    "# plt.hist(batch_ratios, bins=30, edgecolor='black')\n",
    "# plt.xlabel(\"Percentage of 1s in Sequence\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.title(\"Distribution of Sequences with 1s per Batch (Train Set)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable(package='Custom', name='TverskyBCEPerSequence')\n",
    "class TverskyBCEPerSequence(losses.Loss):\n",
    "    def __init__(self, alpha_t=0.5, beta_t=0.5, alpha_f=0.5, gamma_f=0.0, event_weight=1.0, smooth=1e-6, reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, name=\"tversky_bce_per_sequence\"):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "        self.alpha_t = alpha_t\n",
    "        self.beta_t = beta_t\n",
    "        self.alpha_f = alpha_f\n",
    "        self.gamma_f = gamma_f\n",
    "        self.event_weight = event_weight\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
    "        y_pred = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1. - 1e-7)\n",
    "\n",
    "        has_event = tf.cast(tf.reduce_sum(y_true, axis=1) > 0, tf.float32)\n",
    "\n",
    "        tp = tf.reduce_sum(y_true * y_pred, axis=1)\n",
    "        fn = tf.reduce_sum(y_true * (1 - y_pred), axis=1)\n",
    "        fp = tf.reduce_sum((1 - y_true) * y_pred, axis=1)\n",
    "\n",
    "        tversky = (tp + self.smooth) / (tp + self.alpha_t * fp + self.beta_t * fn + self.smooth)\n",
    "        fbce = losses.binary_focal_crossentropy(y_true, y_pred, alpha=self.alpha_f, gamma=self.gamma_f)\n",
    "        \n",
    "        final_loss = has_event * self.event_weight * (1 - tversky) + (1 - has_event) * fbce \n",
    "\n",
    "        return final_loss\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"alpha_t\": self.alpha_t,\n",
    "            \"beta_t\": self.beta_t,\n",
    "            \"alpha_f\": self.alpha_f,\n",
    "            \"gamma_f\": self.gamma_f,\n",
    "            \"event_weight\": self.event_weight,\n",
    "            \"smooth\": self.smooth\n",
    "        })\n",
    "        \n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "input_layer = layers.Input(shape=(n_timesteps, n_features))\n",
    "x = layers.Conv1D(kernel_size=5, filters=64, padding='same', activation='gelu')(input_layer)\n",
    "x = layers.LayerNormalization()(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "attention, attention_weights = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x, return_attention_scores=True)\n",
    "x = layers.Add()([x, attention])\n",
    "x = layers.LayerNormalization()(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "skip = x\n",
    "x = layers.Dense(128, activation='gelu')(x)\n",
    "x = layers.Dense(64, activation='gelu')(x)\n",
    "skip = layers.Dense(64)(skip)\n",
    "x = layers.Concatenate()([x, skip])\n",
    "x = layers.Dense(32, activation='gelu')(x) \n",
    "output_time_layer = layers.TimeDistributed(layers.Dense(1, activation='sigmoid'), name=\"time_output\")(x)\n",
    "x_seq = layers.GlobalAveragePooling1D()(x)\n",
    "output_seq_layer = layers.Dense(1, activation='sigmoid', name=\"sequence_output\")(x_seq)\n",
    "model = models.Model(inputs=input_layer, outputs=[output_time_layer, output_seq_layer])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss={\n",
    "        'time_output': TverskyBCEPerSequence(\n",
    "            alpha_t=0.6,\n",
    "            beta_t=0.7,\n",
    "            alpha_f=0.25,\n",
    "            gamma_f=1.5,\n",
    "            event_weight=1.75), \n",
    "        'sequence_output': losses.Huber()\n",
    "    },\n",
    "    loss_weights={\n",
    "        'time_output': 1.0,\n",
    "        'sequence_output': 1.0\n",
    "    },\n",
    "    metrics={\n",
    "        'time_output': ['accuracy', metrics.Precision(), metrics.Recall()]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=0,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=steps_train_epoch,\n",
    "    callbacks=[lr_schedule],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(\n",
    "#     model,\n",
    "#     to_file=\"model.png\",\n",
    "#     show_shapes=True,\n",
    "#     show_dtype=False,\n",
    "#     show_layer_names=False,\n",
    "#     rankdir=\"TD\",\n",
    "#     expand_nested=False,\n",
    "#     dpi=200,\n",
    "#     show_layer_activations=False,\n",
    "#     show_trainable=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/mosrl_80_all_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probas_raw = model.predict(test_dataset, steps=steps_test_epoch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probas_sqzd = y_pred_probas_raw[0].squeeze(-1)\n",
    "num_windows, window_size = y_pred_probas_sqzd.shape\n",
    "output_len = num_windows * stride + window_size - 39\n",
    "\n",
    "sum_preds = np.zeros(output_len, dtype=y_pred_probas_sqzd.dtype)\n",
    "count_preds = np.zeros(output_len, dtype=int)\n",
    "\n",
    "for win_num in range(num_windows):\n",
    "    start = win_num * stride\n",
    "    end = start + window_size\n",
    "    sum_preds[start:end] += y_pred_probas_sqzd[win_num]\n",
    "    count_preds[start:end] += 1\n",
    "\n",
    "y_pred_probas = np.divide(sum_preds, count_preds, where=count_preds != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_pred = (y_pred_probas >= threshold).astype(int)\n",
    "y_test = y[test_idx[0]:test_idx[1]]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/mosrl_80_all_pred_probas.npy', y_pred_probas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "space_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
